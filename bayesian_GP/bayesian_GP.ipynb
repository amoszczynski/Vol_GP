{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting SPY option chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_chains = {}\n",
    "\n",
    "for file in os.listdir('../option_data/spy_data'):\n",
    "    if file[-4:] == '.csv':\n",
    "                \n",
    "        df = pd.read_csv('../option_data/spy_data/' + file)        \n",
    "        \n",
    "        # moving to datetime and making features\n",
    "        df['quote_datetime'] = pd.to_datetime(df['quote_datetime'])\n",
    "        df['expiration'] = pd.to_datetime(df['expiration'])\n",
    "        df['quote_date'] = df['quote_datetime'][0].date()\n",
    "        df['quote_date'] = pd.to_datetime(df['quote_date'])\n",
    "        \n",
    "        # getting only 4:00 quotes\n",
    "        eod = datetime.datetime.combine(df['quote_datetime'][0].date(), datetime.time(16,0, 0))\n",
    "        df = df.loc[df['quote_datetime'] == eod]\n",
    "        \n",
    "        # getting time to expiration and moneyness\n",
    "        df['T'] = df['expiration'] - df['quote_date']\n",
    "        df['T'] = df['T'].dt.days\n",
    "        df['moneyness'] = df['active_underlying_price'] / df['strike'] \n",
    "        \n",
    "        # converting to ML features\n",
    "        df['T'] = df['T'].astype(np.float32)\n",
    "        df['mny'] = df['moneyness'].astype(np.float32)\n",
    "        df['iv'] = df['implied_volatility'].astype(np.float32)\n",
    "        \n",
    "        # filtering for research paper criteria\n",
    "        df = df.loc[(df['close']!=0) & (df['iv']!=0) & (df['T']>=20) & (df['T']<=365) & (df['mny']>0.7) & (df['mny']<1.3)]\n",
    "                \n",
    "        # splitting up into calls/puts\n",
    "        calls = df.loc[df['option_type']=='C'][['T', 'mny', 'iv']]\n",
    "        puts = df.loc[df['option_type']=='P'][['T', 'mny', 'iv']]\n",
    "        opts = {'calls':calls, 'puts':puts}\n",
    "    \n",
    "        # assinging to date\n",
    "        daily_chains[file[-14:-4]] = opts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'gpytorch.priors.torch_priors',\n",
       "              '__doc__': '\\n    Uniform prior.\\n    ',\n",
       "              '__init__': <function gpytorch.priors.torch_priors.UniformPrior.__init__(self, a, b, validate_args=None, transform=None)>,\n",
       "              'expand': <function gpytorch.priors.torch_priors.UniformPrior.expand(self, batch_shape)>,\n",
       "              '__abstractmethods__': frozenset(),\n",
       "              '_abc_impl': <_abc._abc_data at 0x1559d0fc0>,\n",
       "              '__signature__': <Signature (a, b, validate_args=None, transform=None)>})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniformPrior.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [00:00, 2550.98it/s, step size=1.00e+00, acc. prob=1.000]\n"
     ]
    }
   ],
   "source": [
    "gp_models = {}\n",
    "#likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "#for day, options in daily_chains.items():\n",
    "day, options = list(daily_chains.items())[0]\n",
    "\n",
    "info = {}\n",
    "\n",
    "# calls and puts\n",
    "c = options['calls']\n",
    "p = options['puts']\n",
    "\n",
    "# feature transformations\n",
    "c['mm_T'] = (c['T'] - 20)/(365-20)\n",
    "c['mm_mny'] = (c['mny'] - 0.7)/(1.3-0.7)\n",
    "c['ln_iv'] = np.log(c['iv'])\n",
    "\n",
    "p['mm_T'] = (p['T'] - 20)/(365-20)\n",
    "p['mm_mny'] = (p['mny'] - 0.7)/(1.3-0.7)\n",
    "p['ln_iv'] = np.log(p['iv'])\n",
    "\n",
    "# test/train split\n",
    "c_train, c_test = train_test_split(c, test_size=0.2)\n",
    "p_train, p_test = train_test_split(p, test_size=0.2)\n",
    "info['call_train'] = c_train\n",
    "info['call_test'] = c_test\n",
    "info['put_train'] = p_train\n",
    "info['put_test'] = p_test\n",
    "\n",
    "# into tensors\n",
    "cx_train = torch.tensor(c_train[['mm_T']].values) #, 'mm_mny']].values)\n",
    "cy_train = torch.tensor(c_train[['ln_iv']].values).reshape(len(c_train))\n",
    "cx_test = torch.tensor(c_test[['mm_T', 'mm_mny']].values)\n",
    "cy_test = torch.tensor(c_test[['ln_iv']].values).reshape(len(c_test))\n",
    "\n",
    "px_train = torch.tensor(p_train[['mm_T', 'mm_mny']].values)\n",
    "py_train = torch.tensor(p_train[['ln_iv']].values).reshape(len(p_train))\n",
    "px_test = torch.tensor(p_test[['mm_T', 'mm_mny']].values)\n",
    "py_test = torch.tensor(p_test[['ln_iv']].values).reshape(len(p_test))\n",
    "\n",
    "num_samples = 100\n",
    "warmup_steps = 100\n",
    "\n",
    "# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()#noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(cx_train, cy_train, likelihood)\n",
    "\n",
    "\n",
    "\n",
    "#model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "#model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "\n",
    "\n",
    "#likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "def pyro_model(x, y):\n",
    "    with gpytorch.settings.fast_computations(False, False, False):\n",
    "        sampled_model = model.pyro_sample_from_prior()\n",
    "        output = sampled_model.likelihood(sampled_model(x))\n",
    "        pyro.sample(\"obs\", output, obs=y)\n",
    "    return y\n",
    "\n",
    "nuts_kernel = NUTS(pyro_model)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=False)\n",
    "mcmc_run.run(cx_train, cy_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstantMean(\n",
       "  (mean_prior): UniformPrior(low: 0.0, high: 1.0)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()#noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(cx_train, cy_train, likelihood)\n",
    "\n",
    "\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(0, 1), \"constant\")\n",
    "\n",
    "model.mean_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('raw_constant',\n",
       "              Parameter containing:\n",
       "              tensor(0.1004, requires_grad=True))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior, closure, setting_closure = model.mean_module._priors[\"mean_prior\"]\n",
    "#prior.sample()\n",
    "\n",
    "a= setting_closure(model.mean_module, prior.sample())\n",
    "\n",
    "a._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_RandomExactGPModel(\n",
       "  (likelihood): _RandomGaussianLikelihood(\n",
       "    (noise_covar): _RandomHomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): _RandomConstantMean(\n",
       "    (mean_prior): UniformPrior(low: 0.0, high: 1.0)\n",
       "  )\n",
       "  (covar_module): _RandomScaleKernel(\n",
       "    (base_kernel): _RandomRBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pyro_sample_from_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exactly done as in docs:\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 4)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [00:14, 14.14it/s, step size=4.57e-01, acc. prob=0.959]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "num_samples = 2 if smoke_test else 100\n",
    "warmup_steps = 2 if smoke_test else 100\n",
    "\n",
    "\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "def pyro_model(x, y):\n",
    "    with gpytorch.settings.fast_computations(False, False, False):\n",
    "        sampled_model = model.pyro_sample_from_prior()\n",
    "        output = sampled_model.likelihood(sampled_model(x))\n",
    "        pyro.sample(\"obs\", output, obs=y)\n",
    "    return y\n",
    "\n",
    "nuts_kernel = NUTS(pyro_model)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=smoke_test)\n",
    "mcmc_run.run(train_x, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vol2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
