{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting SPY option chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_chains = {}\n",
    "\n",
    "for file in os.listdir('../option_data/spy_data'):\n",
    "    if file[-4:] == '.csv':\n",
    "                \n",
    "        df = pd.read_csv('../option_data/spy_data/' + file)        \n",
    "        \n",
    "        # moving to datetime and making features\n",
    "        df['quote_datetime'] = pd.to_datetime(df['quote_datetime'])\n",
    "        df['expiration'] = pd.to_datetime(df['expiration'])\n",
    "        df['quote_date'] = df['quote_datetime'][0].date()\n",
    "        df['quote_date'] = pd.to_datetime(df['quote_date'])\n",
    "        \n",
    "        # getting only 4:00 quotes\n",
    "        eod = datetime.datetime.combine(df['quote_datetime'][0].date(), datetime.time(16,0, 0))\n",
    "        df = df.loc[df['quote_datetime'] == eod]\n",
    "        \n",
    "        # getting time to expiration and moneyness\n",
    "        df['T'] = df['expiration'] - df['quote_date']\n",
    "        df['T'] = df['T'].dt.days\n",
    "        df['moneyness'] = df['active_underlying_price'] / df['strike'] \n",
    "        \n",
    "        # converting to ML features\n",
    "        df['T'] = df['T'].astype(np.float32)\n",
    "        df['mny'] = df['moneyness'].astype(np.float32)\n",
    "        df['iv'] = df['implied_volatility'].astype(np.float32)\n",
    "        \n",
    "        # filtering for research paper criteria\n",
    "        df = df.loc[(df['close']!=0) & (df['iv']!=0) & (df['T']>=20) & (df['T']<=365) & (df['mny']>0.7) & (df['mny']<1.3)]\n",
    "                \n",
    "        # splitting up into calls/puts\n",
    "        calls = df.loc[df['option_type']=='C'][['T', 'mny', 'iv']]\n",
    "        puts = df.loc[df['option_type']=='P'][['T', 'mny', 'iv']]\n",
    "        opts = {'calls':calls, 'puts':puts}\n",
    "    \n",
    "        # assinging to date\n",
    "        daily_chains[file[-14:-4]] = opts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02\n",
      "2023-10-03\n",
      "2023-10-04\n",
      "2023-10-05\n",
      "2023-10-06\n",
      "2023-10-09\n",
      "2023-10-10\n",
      "2023-10-11\n",
      "2023-10-12\n",
      "2023-10-13\n",
      "2023-10-16\n",
      "2023-10-17\n",
      "2023-10-18\n",
      "2023-10-19\n",
      "2023-10-20\n",
      "2023-10-23\n",
      "2023-10-24\n",
      "2023-10-25\n",
      "2023-10-26\n",
      "2023-10-27\n",
      "2023-10-30\n",
      "2023-10-31\n"
     ]
    }
   ],
   "source": [
    "_ = [print(k) for k in sorted(daily_chains.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'gpytorch.priors.torch_priors',\n",
       "              '__doc__': '\\n    Uniform prior.\\n    ',\n",
       "              '__init__': <function gpytorch.priors.torch_priors.UniformPrior.__init__(self, a, b, validate_args=None, transform=None)>,\n",
       "              'expand': <function gpytorch.priors.torch_priors.UniformPrior.expand(self, batch_shape)>,\n",
       "              '__abstractmethods__': frozenset(),\n",
       "              '_abc_impl': <_abc._abc_data at 0x1559d0fc0>,\n",
       "              '__signature__': <Signature (a, b, validate_args=None, transform=None)>})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniformPrior.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:52,  1.16s/it, step size=6.52e-01, acc. prob=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:25,  1.37it/s, step size=4.27e-01, acc. prob=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [06:14,  1.87s/it, step size=4.81e-01, acc. prob=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:41,  1.11s/it, step size=5.11e-01, acc. prob=0.888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:42,  1.41s/it, step size=5.45e-01, acc. prob=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:59,  1.11it/s, step size=6.74e-01, acc. prob=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [06:43,  2.02s/it, step size=2.74e-01, acc. prob=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:55,  1.48s/it, step size=4.41e-01, acc. prob=0.933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [09:23,  2.82s/it, step size=1.71e-01, acc. prob=0.549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [2:04:30, 37.35s/it, step size=4.58e-17, acc. prob=0.000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [05:08,  1.54s/it, step size=2.70e-01, acc. prob=0.952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:09,  1.25s/it, step size=3.52e-01, acc. prob=0.963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:16,  1.28s/it, step size=1.99e-01, acc. prob=0.914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:06,  1.58it/s, step size=4.21e-01, acc. prob=0.949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:58,  1.12it/s, step size=4.72e-01, acc. prob=0.933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:18,  1.01it/s, step size=5.34e-01, acc. prob=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:50,  1.15s/it, step size=9.94e-01, acc. prob=0.743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:17,  1.45it/s, step size=1.28e+00, acc. prob=0.608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:34,  1.37s/it, step size=3.58e-01, acc. prob=0.932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:34,  1.07s/it, step size=5.93e-01, acc. prob=0.869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:12,  1.04it/s, step size=9.73e-01, acc. prob=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:36,  1.28it/s, step size=5.13e-01, acc. prob=0.851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [27:05,  8.13s/it, step size=2.55e-01, acc. prob=0.971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [33:16,  9.98s/it, step size=5.06e-01, acc. prob=0.900] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [10:09,  3.05s/it, step size=5.93e-01, acc. prob=0.914] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:06,  1.23s/it, step size=6.44e-01, acc. prob=0.931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [09:41,  2.91s/it, step size=8.98e-01, acc. prob=0.805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:12,  1.04it/s, step size=4.78e-01, acc. prob=0.951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [26:20,  7.90s/it, step size=3.03e-01, acc. prob=0.977] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [18:13,  5.47s/it, step size=4.47e-01, acc. prob=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [07:37,  2.29s/it, step size=7.93e-01, acc. prob=0.888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [06:25,  1.93s/it, step size=3.47e-01, acc. prob=0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [20:00,  6.00s/it, step size=4.21e-01, acc. prob=0.929] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [17:54,  5.37s/it, step size=4.53e-01, acc. prob=0.961]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [10:24,  3.12s/it, step size=5.10e-01, acc. prob=0.857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [09:29,  2.85s/it, step size=5.67e-01, acc. prob=0.880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [02:59,  1.11it/s, step size=7.14e-01, acc. prob=0.847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [03:08,  1.06it/s, step size=3.73e-01, acc. prob=0.950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [04:46,  1.43s/it, step size=6.48e-01, acc. prob=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING PUT MCMC RUN FOR  2023-10-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:  15%|█▌        | 30/200 [01:08,  4.05s/it, step size=4.37e-02, acc. prob=0.751]"
     ]
    }
   ],
   "source": [
    "gp_models = {}\n",
    "#likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# #for day, options in daily_chains.items():\n",
    "    # day, options = list(daily_chains.items())[0]\n",
    "\n",
    "\n",
    "for day, options in daily_chains.items():\n",
    "    \n",
    "    info = {}\n",
    "\n",
    "    # calls and puts\n",
    "    c = options['calls']\n",
    "    p = options['puts']\n",
    "\n",
    "    # feature transformations\n",
    "    c['mm_T'] = (c['T'] - 20)/(365-20)\n",
    "    c['mm_mny'] = (c['mny'] - 0.7)/(1.3-0.7)\n",
    "    c['ln_iv'] = np.log(c['iv'])\n",
    "\n",
    "    p['mm_T'] = (p['T'] - 20)/(365-20)\n",
    "    p['mm_mny'] = (p['mny'] - 0.7)/(1.3-0.7)\n",
    "    p['ln_iv'] = np.log(p['iv'])\n",
    "\n",
    "    # test/train split\n",
    "    c_train, c_test = train_test_split(c, test_size=0.2)\n",
    "    p_train, p_test = train_test_split(p, test_size=0.2)\n",
    "    info['call_train'] = c_train\n",
    "    info['call_test'] = c_test\n",
    "    info['put_train'] = p_train\n",
    "    info['put_test'] = p_test\n",
    "\n",
    "    # into tensors\n",
    "    cx_train = torch.tensor(c_train[['mm_T']].values) #, 'mm_mny']].values)\n",
    "    cy_train = torch.tensor(c_train[['ln_iv']].values).reshape(len(c_train))\n",
    "    cx_test = torch.tensor(c_test[['mm_T', 'mm_mny']].values)\n",
    "    cy_test = torch.tensor(c_test[['ln_iv']].values).reshape(len(c_test))\n",
    "\n",
    "    px_train = torch.tensor(p_train[['mm_T', 'mm_mny']].values)\n",
    "    py_train = torch.tensor(p_train[['ln_iv']].values).reshape(len(p_train))\n",
    "    px_test = torch.tensor(p_test[['mm_T', 'mm_mny']].values)\n",
    "    py_test = torch.tensor(p_test[['ln_iv']].values).reshape(len(p_test))\n",
    "\n",
    "    num_samples = 100\n",
    "    warmup_steps = 100\n",
    "\n",
    "    # Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "    c_likelihood = gpytorch.likelihoods.GaussianLikelihood()#noise_constraint=gpytorch.constraints.Positive())\n",
    "    c_model = ExactGPModel(cx_train, cy_train, c_likelihood)\n",
    "    \n",
    "    p_likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    p_model = ExactGPModel(px_train, py_train, p_likelihood)\n",
    "\n",
    "    #model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    #model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "\n",
    "    #likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "    # prepare priors\n",
    "    c_model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "    c_model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    c_model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "    c_likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "    p_model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "    p_model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    p_model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "    p_likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "    # define mlls\n",
    "    c_mll = gpytorch.mlls.ExactMarginalLogLikelihood(c_likelihood, c_model)\n",
    "    p_mll = gpytorch.mlls.ExactMarginalLogLikelihood(p_likelihood, p_model)\n",
    "\n",
    "    # define pyro model\n",
    "    def c_pyro_model(x, y):\n",
    "        with gpytorch.settings.fast_computations(False, False, False):\n",
    "            sampled_model = c_model.pyro_sample_from_prior()\n",
    "            output = sampled_model.likelihood(sampled_model(x))\n",
    "            pyro.sample(\"obs\", output, obs=y)\n",
    "        return y\n",
    "    \n",
    "    # define pyro for p too, maybe better way to do this but wasnt sure \n",
    "    # if i could pass the model and still have it work\n",
    "    def p_pyro_model(x, y):\n",
    "        with gpytorch.settings.fast_computations(False, False, False):\n",
    "            sampled_model = p_model.pyro_sample_from_prior()\n",
    "            output = sampled_model.likelihood(sampled_model(x))\n",
    "            pyro.sample(\"obs\", output, obs=y)\n",
    "        return y\n",
    "\n",
    "    print('STARTING CALL MCMC RUN FOR ', day)\n",
    "\n",
    "    # set no u-turn sampler for HMC\n",
    "    c_nuts_kernel = NUTS(c_pyro_model)\n",
    "    # run mcmc to convergence\n",
    "    c_mcmc_run = MCMC(c_nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=False)\n",
    "    c_mcmc_run.run(cx_train, cy_train)\n",
    "    \n",
    "    print('STARTING PUT MCMC RUN FOR ', day)\n",
    "\n",
    "    # set no u-turn sampler for HMC\n",
    "    p_nuts_kernel = NUTS(p_pyro_model)\n",
    "    p_mcmc_run = MCMC(p_nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=False)\n",
    "    # run mcmc to convergence\n",
    "    p_mcmc_run.run(px_train, py_train)\n",
    "\n",
    "    # # set to eval mode\n",
    "    # c_model.eval()\n",
    "    # p_model.eval()\n",
    "    \n",
    "\n",
    "\n",
    "    # # get samples and predictions\n",
    "    # with torch.no_grad():\n",
    "    #     # get samples\n",
    "    #     c_samples = c_mcmc_run.get_samples()\n",
    "    #     p_samples = p_mcmc_run.get_samples()\n",
    "\n",
    "    #     # get predictions\n",
    "    #     c_pred = c_likelihood(c_model(cx_test))\n",
    "    #     p_pred = p_likelihood(p_model(px_test))\n",
    "    \n",
    "    # # save above\n",
    "    # info['call_samples'] = c_samples\n",
    "    # info['put_samples'] = p_samples\n",
    "    \n",
    "    # info['call_pred'] = c_pred\n",
    "    # info['put_pred'] = p_pred\n",
    "\n",
    "    # # getting RMSE\n",
    "    # c_rmse = torch.sqrt(torch.mean(torch.pow(math.e ** c_pred.mean - math.e ** cy_test, 2)))\n",
    "    # p_rmse = torch.sqrt(torch.mean(torch.pow(math.e ** p_pred.mean - math.e ** py_test, 2)))\n",
    "    # info['call_RMSE'] = c_rmse\n",
    "    # info['put_RMSE'] = p_rmse\n",
    "\n",
    "    # save samples\n",
    "    info['call_samples'] = c_mcmc_run.get_samples()\n",
    "    info['put_samples'] = p_mcmc_run.get_samples()\n",
    "\n",
    "    torch.save(c_mcmc_run.get_samples(), 'samples/call_BGP_'+day+'.pt')\n",
    "    torch.save(p_mcmc_run.get_samples(), 'samples/put_BGP_'+day+'.pt')\n",
    "\n",
    "    # save likelihoods\n",
    "    info['call_likelihood'] = c_likelihood\n",
    "    info['put_likelihood'] = p_likelihood\n",
    "\n",
    "    # save models\n",
    "    torch.save(c_model.state_dict(), 'models/call_BGP_'+day+'.pt')\n",
    "    torch.save(p_model.state_dict(), 'models/put_BGP_'+day+'.pt')\n",
    "\n",
    "    gp_models[day] = info\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstantMean(\n",
       "  (mean_prior): UniformPrior(low: 0.0, high: 1.0)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()#noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(cx_train, cy_train, likelihood)\n",
    "\n",
    "\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(0, 1), \"constant\")\n",
    "\n",
    "model.mean_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('raw_constant',\n",
       "              Parameter containing:\n",
       "              tensor(0.1004, requires_grad=True))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior, closure, setting_closure = model.mean_module._priors[\"mean_prior\"]\n",
    "#prior.sample()\n",
    "\n",
    "a= setting_closure(model.mean_module, prior.sample())\n",
    "\n",
    "a._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_RandomExactGPModel(\n",
       "  (likelihood): _RandomGaussianLikelihood(\n",
       "    (noise_covar): _RandomHomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): _RandomConstantMean(\n",
       "    (mean_prior): UniformPrior(low: 0.0, high: 1.0)\n",
       "  )\n",
       "  (covar_module): _RandomScaleKernel(\n",
       "    (base_kernel): _RandomRBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pyro_sample_from_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exactly done as in docs:\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 4)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 200/200 [00:14, 14.14it/s, step size=4.57e-01, acc. prob=0.959]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "num_samples = 2 if smoke_test else 100\n",
    "warmup_steps = 2 if smoke_test else 100\n",
    "\n",
    "\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "def pyro_model(x, y):\n",
    "    with gpytorch.settings.fast_computations(False, False, False):\n",
    "        sampled_model = model.pyro_sample_from_prior()\n",
    "        output = sampled_model.likelihood(sampled_model(x))\n",
    "        pyro.sample(\"obs\", output, obs=y)\n",
    "    return y\n",
    "\n",
    "nuts_kernel = NUTS(pyro_model)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=smoke_test)\n",
    "mcmc_run.run(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vol2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
