{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting SPY option chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_chains = {}\n",
    "\n",
    "for file in os.listdir('../option_data/spy_data'):\n",
    "    if file[-4:] == '.csv':\n",
    "                \n",
    "        df = pd.read_csv('../option_data/spy_data/' + file)        \n",
    "        \n",
    "        # moving to datetime and making features\n",
    "        df['quote_datetime'] = pd.to_datetime(df['quote_datetime'])\n",
    "        df['expiration'] = pd.to_datetime(df['expiration'])\n",
    "        df['quote_date'] = df['quote_datetime'][0].date()\n",
    "        df['quote_date'] = pd.to_datetime(df['quote_date'])\n",
    "        \n",
    "        # getting only 4:00 quotes\n",
    "        eod = datetime.datetime.combine(df['quote_datetime'][0].date(), datetime.time(16,0, 0))\n",
    "        df = df.loc[df['quote_datetime'] == eod]\n",
    "        \n",
    "        # getting time to expiration and moneyness\n",
    "        df['T'] = df['expiration'] - df['quote_date']\n",
    "        df['T'] = df['T'].dt.days\n",
    "        df['moneyness'] = df['active_underlying_price'] / df['strike'] \n",
    "        \n",
    "        # converting to ML features\n",
    "        df['T'] = df['T'].astype(np.float32)\n",
    "        df['mny'] = df['moneyness'].astype(np.float32)\n",
    "        df['iv'] = df['implied_volatility'].astype(np.float32)\n",
    "        \n",
    "        # filtering for research paper criteria\n",
    "        df = df.loc[(df['close']!=0) & (df['iv']!=0) & (df['T']>=20) & (df['T']<=365) & (df['mny']>0.7) & (df['mny']<1.3)]\n",
    "                \n",
    "        # splitting up into calls/puts\n",
    "        calls = df.loc[df['option_type']=='C'][['T', 'mny', 'iv']]\n",
    "        puts = df.loc[df['option_type']=='P'][['T', 'mny', 'iv']]\n",
    "        opts = {'calls':calls, 'puts':puts}\n",
    "    \n",
    "        # assinging to date\n",
    "        daily_chains[file[-14:-4]] = opts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-02\n",
      "2023-10-03\n",
      "2023-10-04\n",
      "2023-10-05\n",
      "2023-10-06\n",
      "2023-10-09\n",
      "2023-10-10\n",
      "2023-10-11\n",
      "2023-10-12\n",
      "2023-10-13\n",
      "2023-10-16\n",
      "2023-10-17\n",
      "2023-10-18\n",
      "2023-10-19\n",
      "2023-10-20\n",
      "2023-10-23\n",
      "2023-10-24\n",
      "2023-10-25\n",
      "2023-10-26\n",
      "2023-10-27\n",
      "2023-10-30\n",
      "2023-10-31\n"
     ]
    }
   ],
   "source": [
    "_ = [print(k) for k in sorted(daily_chains.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'gpytorch.priors.torch_priors',\n",
       "              '__doc__': '\\n    Uniform prior.\\n    ',\n",
       "              '__init__': <function gpytorch.priors.torch_priors.UniformPrior.__init__(self, a, b, validate_args=None, transform=None)>,\n",
       "              'expand': <function gpytorch.priors.torch_priors.UniformPrior.expand(self, batch_shape)>,\n",
       "              '__abstractmethods__': frozenset(),\n",
       "              '_abc_impl': <_abc._abc_data at 0x1559d0fc0>,\n",
       "              '__signature__': <Signature (a, b, validate_args=None, transform=None)>})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UniformPrior.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING CALL MCMC RUN FOR  2023-10-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   8%|â–Š         | 15/200 [00:26,  2.69s/it, step size=2.78e-01, acc. prob=0.768]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m# run mcmc to convergence\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m c_mcmc_run \u001b[39m=\u001b[39m MCMC(c_nuts_kernel, num_samples\u001b[39m=\u001b[39mnum_samples, warmup_steps\u001b[39m=\u001b[39mwarmup_steps, disable_progbar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m c_mcmc_run\u001b[39m.\u001b[39mrun(cx_train, cy_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSTARTING PUT MCMC RUN FOR \u001b[39m\u001b[39m'\u001b[39m, day)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39m# set no u-turn sampler for HMC\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/api.py:563\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39mwith\u001b[39;00m optional(\n\u001b[1;32m    555\u001b[0m     pyro\u001b[39m.\u001b[39mvalidation_enabled(\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable_validation),\n\u001b[1;32m    556\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable_validation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[39m# This also resolves \"RuntimeError: Cowardly refusing to serialize non-leaf tensor which\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[39m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     args \u001b[39m=\u001b[39m [arg\u001b[39m.\u001b[39mdetach() \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(arg) \u001b[39melse\u001b[39;00m arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m x, chain_id \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampler\u001b[39m.\u001b[39mrun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m num_samples[chain_id] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    565\u001b[0m             num_samples[chain_id] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/api.py:223\u001b[0m, in \u001b[0;36m_UnarySampler.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m logger \u001b[39m=\u001b[39m initialize_logger(logger, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, progress_bar)\n\u001b[1;32m    222\u001b[0m hook_w_logging \u001b[39m=\u001b[39m _add_logging_hook(logger, progress_bar, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook)\n\u001b[0;32m--> 223\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m _gen_samples(\n\u001b[1;32m    224\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel,\n\u001b[1;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarmup_steps,\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples,\n\u001b[1;32m    227\u001b[0m     hook_w_logging,\n\u001b[1;32m    228\u001b[0m     i \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_chains \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    229\u001b[0m     \u001b[39m*\u001b[39margs,\n\u001b[1;32m    230\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    231\u001b[0m ):\n\u001b[1;32m    232\u001b[0m     \u001b[39myield\u001b[39;00m sample, i  \u001b[39m# sample, chain_id\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/api.py:150\u001b[0m, in \u001b[0;36m_gen_samples\u001b[0;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39myield\u001b[39;00m {name: params[name]\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m save_params}\n\u001b[1;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(warmup_steps):\n\u001b[0;32m--> 150\u001b[0m     params \u001b[39m=\u001b[39m kernel\u001b[39m.\u001b[39msample(params)\n\u001b[1;32m    151\u001b[0m     hook(\n\u001b[1;32m    152\u001b[0m         kernel,\n\u001b[1;32m    153\u001b[0m         params,\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWarmup [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(chain_id) \u001b[39mif\u001b[39;00m chain_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mWarmup\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         i,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:437\u001b[0m, in \u001b[0;36mNUTS.sample\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    433\u001b[0m direction \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(direction\u001b[39m.\u001b[39mitem())\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    435\u001b[0m     direction \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    436\u001b[0m ):  \u001b[39m# go to the right, start from the right leaf of current tree\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     new_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    438\u001b[0m         z_right,\n\u001b[1;32m    439\u001b[0m         r_right,\n\u001b[1;32m    440\u001b[0m         z_right_grads,\n\u001b[1;32m    441\u001b[0m         log_slice,\n\u001b[1;32m    442\u001b[0m         direction,\n\u001b[1;32m    443\u001b[0m         tree_depth,\n\u001b[1;32m    444\u001b[0m         energy_current,\n\u001b[1;32m    445\u001b[0m     )\n\u001b[1;32m    446\u001b[0m     \u001b[39m# update leaf for the next doubling process\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     z_right \u001b[39m=\u001b[39m new_tree\u001b[39m.\u001b[39mz_right\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:259\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_basetree(\n\u001b[1;32m    255\u001b[0m         z, r, z_grads, log_slice, direction, energy_current\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39m# build the first half of tree\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    260\u001b[0m     z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m z_proposal \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal\n\u001b[1;32m    263\u001b[0m z_proposal_pe \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal_pe\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:281\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    279\u001b[0m     r \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mr_left\n\u001b[1;32m    280\u001b[0m     z_grads \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_left_grads\n\u001b[0;32m--> 281\u001b[0m other_half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    282\u001b[0m     z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_multinomial_sampling:\n\u001b[1;32m    286\u001b[0m     tree_weight \u001b[39m=\u001b[39m _logaddexp(half_tree\u001b[39m.\u001b[39mweight, other_half_tree\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:259\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_basetree(\n\u001b[1;32m    255\u001b[0m         z, r, z_grads, log_slice, direction, energy_current\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39m# build the first half of tree\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    260\u001b[0m     z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m z_proposal \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal\n\u001b[1;32m    263\u001b[0m z_proposal_pe \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal_pe\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:259\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_basetree(\n\u001b[1;32m    255\u001b[0m         z, r, z_grads, log_slice, direction, energy_current\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39m# build the first half of tree\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    260\u001b[0m     z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m z_proposal \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal\n\u001b[1;32m    263\u001b[0m z_proposal_pe \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal_pe\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:259\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_basetree(\n\u001b[1;32m    255\u001b[0m         z, r, z_grads, log_slice, direction, energy_current\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m \u001b[39m# build the first half of tree\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    260\u001b[0m     z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m z_proposal \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal\n\u001b[1;32m    263\u001b[0m z_proposal_pe \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_proposal_pe\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:281\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    279\u001b[0m     r \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mr_left\n\u001b[1;32m    280\u001b[0m     z_grads \u001b[39m=\u001b[39m half_tree\u001b[39m.\u001b[39mz_left_grads\n\u001b[0;32m--> 281\u001b[0m other_half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    282\u001b[0m     z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_multinomial_sampling:\n\u001b[1;32m    286\u001b[0m     tree_weight \u001b[39m=\u001b[39m _logaddexp(half_tree\u001b[39m.\u001b[39mweight, other_half_tree\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:254\u001b[0m, in \u001b[0;36mNUTS._build_tree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_tree\u001b[39m(\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m, z, r, z_grads, log_slice, direction, tree_depth, energy_current\n\u001b[1;32m    252\u001b[0m ):\n\u001b[1;32m    253\u001b[0m     \u001b[39mif\u001b[39;00m tree_depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 254\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_basetree(\n\u001b[1;32m    255\u001b[0m             z, r, z_grads, log_slice, direction, energy_current\n\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    258\u001b[0m     \u001b[39m# build the first half of tree\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     half_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_tree(\n\u001b[1;32m    260\u001b[0m         z, r, z_grads, log_slice, direction, tree_depth \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, energy_current\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/nuts.py:199\u001b[0m, in \u001b[0;36mNUTS._build_basetree\u001b[0;34m(self, z, r, z_grads, log_slice, direction, energy_current)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_basetree\u001b[39m(\u001b[39mself\u001b[39m, z, r, z_grads, log_slice, direction, energy_current):\n\u001b[1;32m    198\u001b[0m     step_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_size \u001b[39mif\u001b[39;00m direction \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_size\n\u001b[0;32m--> 199\u001b[0m     z_new, r_new, z_grads, potential_energy \u001b[39m=\u001b[39m velocity_verlet(\n\u001b[1;32m    200\u001b[0m         z,\n\u001b[1;32m    201\u001b[0m         r,\n\u001b[1;32m    202\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpotential_fn,\n\u001b[1;32m    203\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmass_matrix_adapter\u001b[39m.\u001b[39mkinetic_grad,\n\u001b[1;32m    204\u001b[0m         step_size,\n\u001b[1;32m    205\u001b[0m         z_grads\u001b[39m=\u001b[39mz_grads,\n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    207\u001b[0m     r_new_unscaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmass_matrix_adapter\u001b[39m.\u001b[39munscale(r_new)\n\u001b[1;32m    208\u001b[0m     energy_new \u001b[39m=\u001b[39m potential_energy \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kinetic_energy(r_new_unscaled)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/ops/integrator.py:39\u001b[0m, in \u001b[0;36mvelocity_verlet\u001b[0;34m(z, r, potential_fn, kinetic_grad, step_size, num_steps, z_grads)\u001b[0m\n\u001b[1;32m     37\u001b[0m r_next \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 39\u001b[0m     z_next, r_next, z_grads, potential_energy \u001b[39m=\u001b[39m _single_step_verlet(\n\u001b[1;32m     40\u001b[0m         z_next, r_next, potential_fn, kinetic_grad, step_size, z_grads\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m z_next, r_next, z_grads, potential_energy\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/ops/integrator.py:61\u001b[0m, in \u001b[0;36m_single_step_verlet\u001b[0;34m(z, r, potential_fn, kinetic_grad, step_size, z_grads)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m site_name \u001b[39min\u001b[39;00m z:\n\u001b[1;32m     59\u001b[0m     z[site_name] \u001b[39m=\u001b[39m z[site_name] \u001b[39m+\u001b[39m step_size \u001b[39m*\u001b[39m r_grads[site_name]  \u001b[39m# z(n+1)\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m z_grads, potential_energy \u001b[39m=\u001b[39m potential_grad(potential_fn, z)\n\u001b[1;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m site_name \u001b[39min\u001b[39;00m r:\n\u001b[1;32m     63\u001b[0m     r[site_name] \u001b[39m=\u001b[39m r[site_name] \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m step_size \u001b[39m*\u001b[39m (\u001b[39m-\u001b[39mz_grads[site_name])  \u001b[39m# r(n+1)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/ops/integrator.py:83\u001b[0m, in \u001b[0;36mpotential_grad\u001b[0;34m(potential_fn, z)\u001b[0m\n\u001b[1;32m     81\u001b[0m     node\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     potential_energy \u001b[39m=\u001b[39m potential_fn(z)\n\u001b[1;32m     84\u001b[0m \u001b[39m# handle exceptions as defined in the exception registry\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/infer/mcmc/util.py:278\u001b[0m, in \u001b[0;36m_PEMaker._potential_fn\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    276\u001b[0m params_constrained \u001b[39m=\u001b[39m {k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms[k]\u001b[39m.\u001b[39minv(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    277\u001b[0m cond_model \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39mcondition(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, params_constrained)\n\u001b[0;32m--> 278\u001b[0m model_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39mtrace(cond_model)\u001b[39m.\u001b[39mget_trace(\n\u001b[1;32m    279\u001b[0m     \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_kwargs\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m log_joint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_prob_evaluator\u001b[39m.\u001b[39mlog_prob(model_trace)\n\u001b[1;32m    282\u001b[0m \u001b[39mfor\u001b[39;00m name, t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mc_pyro_model\u001b[39m(x, y):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39mwith\u001b[39;00m gpytorch\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mfast_computations(\u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m         sampled_model \u001b[39m=\u001b[39m c_model\u001b[39m.\u001b[39mpyro_sample_from_prior()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m         output \u001b[39m=\u001b[39m sampled_model\u001b[39m.\u001b[39mlikelihood(sampled_model(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/andrewcarranti/CODE/F23_CODE/SENIOR_D/code/Vol_GP/bayesian_GP/bayesian_GP.ipynb#X10sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m         pyro\u001b[39m.\u001b[39msample(\u001b[39m\"\u001b[39m\u001b[39mobs\u001b[39m\u001b[39m\"\u001b[39m, output, obs\u001b[39m=\u001b[39my)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/gpytorch/module.py:386\u001b[0m, in \u001b[0;36mModule.pyro_sample_from_prior\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpyro_sample_from_prior\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    379\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m    For each parameter in this Module and submodule that have defined priors, sample a value for that parameter\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m    from its corresponding prior with a pyro.sample primitive and load the resulting value in to the parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m    parameters of the model that have GPyTorch priors registered to them.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     new_module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_pyro_random_module()\n\u001b[1;32m    387\u001b[0m     \u001b[39mreturn\u001b[39;00m _pyro_sample_from_prior(module\u001b[39m=\u001b[39mnew_module, memo\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/gpytorch/module.py:361\u001b[0m, in \u001b[0;36mModule.to_pyro_random_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_pyro_random_module\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 361\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_random_module()\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/gpytorch/module.py:374\u001b[0m, in \u001b[0;36mModule.to_random_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mfor\u001b[39;00m mname, child \u001b[39min\u001b[39;00m new_module\u001b[39m.\u001b[39mnamed_children():\n\u001b[1;32m    373\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, Module):\n\u001b[0;32m--> 374\u001b[0m         \u001b[39msetattr\u001b[39m(new_module, mname, child\u001b[39m.\u001b[39mto_random_module())\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m new_module\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/gpytorch/module.py:374\u001b[0m, in \u001b[0;36mModule.to_random_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mfor\u001b[39;00m mname, child \u001b[39min\u001b[39;00m new_module\u001b[39m.\u001b[39mnamed_children():\n\u001b[1;32m    373\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(child, Module):\n\u001b[0;32m--> 374\u001b[0m         \u001b[39msetattr\u001b[39m(new_module, mname, child\u001b[39m.\u001b[39mto_random_module())\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m new_module\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/site-packages/gpytorch/module.py:366\u001b[0m, in \u001b[0;36mModule.to_random_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    364\u001b[0m random_module_cls \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_Random\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, (RandomModuleMixin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m), {})\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, random_module_cls):\n\u001b[0;32m--> 366\u001b[0m     new_module \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m    367\u001b[0m     new_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39m=\u001b[39m random_module_cls  \u001b[39m# hack\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[39m# Unclear if this branch would ever get used in practice, but it semantically makes sense to have.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/miniconda3/envs/seniord/lib/python3.11/copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m reductor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__reduce_ex__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m reductor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     rv \u001b[39m=\u001b[39m reductor(\u001b[39m4\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     reductor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__reduce__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gp_models = {}\n",
    "#likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "\n",
    "# #for day, options in daily_chains.items():\n",
    "    # day, options = list(daily_chains.items())[0]\n",
    "\n",
    "\n",
    "for day, options in daily_chains.items():\n",
    "    \n",
    "    info = {}\n",
    "\n",
    "    # calls and puts\n",
    "    c = options['calls']\n",
    "    p = options['puts']\n",
    "\n",
    "    # feature transformations\n",
    "    c['mm_T'] = (c['T'] - 20)/(365-20)\n",
    "    c['mm_mny'] = (c['mny'] - 0.7)/(1.3-0.7)\n",
    "    c['ln_iv'] = np.log(c['iv'])\n",
    "\n",
    "    p['mm_T'] = (p['T'] - 20)/(365-20)\n",
    "    p['mm_mny'] = (p['mny'] - 0.7)/(1.3-0.7)\n",
    "    p['ln_iv'] = np.log(p['iv'])\n",
    "\n",
    "    # test/train split\n",
    "    c_train, c_test = train_test_split(c, test_size=0.2)\n",
    "    p_train, p_test = train_test_split(p, test_size=0.2)\n",
    "    info['call_train'] = c_train\n",
    "    info['call_test'] = c_test\n",
    "    info['put_train'] = p_train\n",
    "    info['put_test'] = p_test\n",
    "\n",
    "    # into tensors\n",
    "    cx_train = torch.tensor(c_train[['mm_T']].values) #, 'mm_mny']].values)\n",
    "    cy_train = torch.tensor(c_train[['ln_iv']].values).reshape(len(c_train))\n",
    "    cx_test = torch.tensor(c_test[['mm_T', 'mm_mny']].values)\n",
    "    cy_test = torch.tensor(c_test[['ln_iv']].values).reshape(len(c_test))\n",
    "\n",
    "    px_train = torch.tensor(p_train[['mm_T', 'mm_mny']].values)\n",
    "    py_train = torch.tensor(p_train[['ln_iv']].values).reshape(len(p_train))\n",
    "    px_test = torch.tensor(p_test[['mm_T', 'mm_mny']].values)\n",
    "    py_test = torch.tensor(p_test[['ln_iv']].values).reshape(len(p_test))\n",
    "\n",
    "    num_samples = 100\n",
    "    warmup_steps = 100\n",
    "\n",
    "    # Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "    c_likelihood = gpytorch.likelihoods.GaussianLikelihood()#noise_constraint=gpytorch.constraints.Positive())\n",
    "    c_model = ExactGPModel(cx_train, cy_train, c_likelihood)\n",
    "    \n",
    "    p_likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    p_model = ExactGPModel(px_train, py_train, p_likelihood)\n",
    "\n",
    "    #model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    #model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "\n",
    "    #likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "    # prepare priors\n",
    "    c_model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "    c_model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    c_model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "    c_likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "    p_model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "    p_model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "    p_model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "    p_likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "    c_mll = gpytorch.mlls.ExactMarginalLogLikelihood(c_likelihood, c_model)\n",
    "    p_mll = gpytorch.mlls.ExactMarginalLogLikelihood(p_likelihood, p_model)\n",
    "\n",
    "\n",
    "    def c_pyro_model(x, y):\n",
    "        with gpytorch.settings.fast_computations(False, False, False):\n",
    "            sampled_model = c_model.pyro_sample_from_prior()\n",
    "            output = sampled_model.likelihood(sampled_model(x))\n",
    "            pyro.sample(\"obs\", output, obs=y)\n",
    "        return y\n",
    "    \n",
    "    # define pyro for p too, maybe better way to do this but wasnt sure \n",
    "    # if i could pass the model and still have it work\n",
    "    def p_pyro_model(x, y):\n",
    "        with gpytorch.settings.fast_computations(False, False, False):\n",
    "            sampled_model = p_model.pyro_sample_from_prior()\n",
    "            output = sampled_model.likelihood(sampled_model(x))\n",
    "            pyro.sample(\"obs\", output, obs=y)\n",
    "        return y\n",
    "\n",
    "    print('STARTING CALL MCMC RUN FOR ', day)\n",
    "\n",
    "    # set no u-turn sampler for HMC\n",
    "    c_nuts_kernel = NUTS(c_pyro_model)\n",
    "    # run mcmc to convergence\n",
    "    c_mcmc_run = MCMC(c_nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=False)\n",
    "    c_mcmc_run.run(cx_train, cy_train)\n",
    "    \n",
    "    print('STARTING PUT MCMC RUN FOR ', day)\n",
    "\n",
    "    # set no u-turn sampler for HMC\n",
    "    p_nuts_kernel = NUTS(p_pyro_model)\n",
    "    p_mcmc_run = MCMC(p_nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=False)\n",
    "    # run mcmc to convergence\n",
    "    p_mcmc_run.run(px_train, py_train)\n",
    "\n",
    "    # # set to eval mode\n",
    "    # c_model.eval()\n",
    "    # p_model.eval()\n",
    "    \n",
    "\n",
    "\n",
    "    # # get samples and predictions\n",
    "    # with torch.no_grad():\n",
    "    #     # get samples\n",
    "    #     c_samples = c_mcmc_run.get_samples()\n",
    "    #     p_samples = p_mcmc_run.get_samples()\n",
    "\n",
    "    #     # get predictions\n",
    "    #     c_pred = c_likelihood(c_model(cx_test))\n",
    "    #     p_pred = p_likelihood(p_model(px_test))\n",
    "    \n",
    "    # # save above\n",
    "    # info['call_samples'] = c_samples\n",
    "    # info['put_samples'] = p_samples\n",
    "    \n",
    "    # info['call_pred'] = c_pred\n",
    "    # info['put_pred'] = p_pred\n",
    "\n",
    "    # # getting RMSE\n",
    "    # c_rmse = torch.sqrt(torch.mean(torch.pow(math.e ** c_pred.mean - math.e ** cy_test, 2)))\n",
    "    # p_rmse = torch.sqrt(torch.mean(torch.pow(math.e ** p_pred.mean - math.e ** py_test, 2)))\n",
    "    # info['call_RMSE'] = c_rmse\n",
    "    # info['put_RMSE'] = p_rmse\n",
    "\n",
    "    # save samples\n",
    "    info['call_samples'] = c_mcmc_run.get_samples()\n",
    "    info['put_samples'] = p_mcmc_run.get_samples()\n",
    "\n",
    "    torch.save(c_mcmc_run.get_samples(), 'samples/call_BGP_'+day+'.pt')\n",
    "    torch.save(p_mcmc_run.get_samples(), 'samples/put_BGP_'+day+'.pt')\n",
    "\n",
    "    # save likelihoods\n",
    "    info['call_likelihood'] = c_likelihood\n",
    "    info['put_likelihood'] = p_likelihood\n",
    "\n",
    "    # save models\n",
    "    torch.save(c_model.state_dict(), 'models/call_BGP_'+day+'.pt')\n",
    "    torch.save(p_model.state_dict(), 'models/put_BGP_'+day+'.pt')\n",
    "\n",
    "    gp_models[day] = info\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConstantMean(\n",
       "  (mean_prior): UniformPrior(low: 0.0, high: 1.0)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()#noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(cx_train, cy_train, likelihood)\n",
    "\n",
    "\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(0, 1), \"constant\")\n",
    "\n",
    "model.mean_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('raw_constant',\n",
       "              Parameter containing:\n",
       "              tensor(0.1004, requires_grad=True))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior, closure, setting_closure = model.mean_module._priors[\"mean_prior\"]\n",
    "#prior.sample()\n",
    "\n",
    "a= setting_closure(model.mean_module, prior.sample())\n",
    "\n",
    "a._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_RandomExactGPModel(\n",
       "  (likelihood): _RandomGaussianLikelihood(\n",
       "    (noise_covar): _RandomHomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (mean_module): _RandomConstantMean(\n",
       "    (mean_prior): UniformPrior(low: 0.0, high: 1.0)\n",
       "  )\n",
       "  (covar_module): _RandomScaleKernel(\n",
       "    (base_kernel): _RandomRBFKernel(\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pyro_sample_from_prior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exactly done as in docs:\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pyro\n",
    "from pyro.infer.mcmc import NUTS, MCMC, HMC\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 4)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:14, 14.14it/s, step size=4.57e-01, acc. prob=0.959]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "num_samples = 2 if smoke_test else 100\n",
    "warmup_steps = 2 if smoke_test else 100\n",
    "\n",
    "\n",
    "from gpytorch.priors import LogNormalPrior, NormalPrior, UniformPrior\n",
    "# Use a positive constraint instead of usual GreaterThan(1e-4) so that LogNormal has support over full range.\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_constraint=gpytorch.constraints.Positive())\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "\n",
    "model.mean_module.register_prior(\"mean_prior\", UniformPrior(-1, 1), \"constant\")\n",
    "model.covar_module.base_kernel.register_prior(\"lengthscale_prior\", UniformPrior(0.01, 0.5), \"lengthscale\")\n",
    "model.covar_module.register_prior(\"outputscale_prior\", UniformPrior(1, 2), \"outputscale\")\n",
    "likelihood.register_prior(\"noise_prior\", UniformPrior(0.01, 0.5), \"noise\")\n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "def pyro_model(x, y):\n",
    "    with gpytorch.settings.fast_computations(False, False, False):\n",
    "        sampled_model = model.pyro_sample_from_prior()\n",
    "        output = sampled_model.likelihood(sampled_model(x))\n",
    "        pyro.sample(\"obs\", output, obs=y)\n",
    "    return y\n",
    "\n",
    "nuts_kernel = NUTS(pyro_model)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=smoke_test)\n",
    "mcmc_run.run(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vol2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
